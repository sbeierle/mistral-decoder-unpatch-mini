# ๐ง Neuron Interference โ Precision Limits of Patching | ุงูุชุฏุงุฎู ุงูุนุตุจู โ ุญุฏูุฏ ุงูุฏูุฉ

## English ๐ฌ๐ง

This file explains a fundamental constraint in decoder patching:
Why canโt we always achieve 100% reversibility, even with clean revert patches?

---

### โ What is Neuron Interference?

In high-dimensional vector spaces (like in LLMs), **individual neurons are rarely isolated**.  
Each neuron's activation contributes **non-linearly and contextually** to downstream outputs.  
Thus, altering one neuron can slightly affect others โ especially when:

- Nearby dimensions have similar weight directions  
- Activation overlaps occur within a transformer layer  
- Post-layernorm interactions amplify subtle effects

---

### ๐ฏ Reverting โ Undoing

Even if we revert the scale of a neuron (e.g. from 0.04 โ 1.0),  
we canโt fully reverse **activation state drift** that already propagated during inference or patch application.

This is not a bug โ itโs a **property of entangled vector spaces**.

---

### ๐งฌ Matrix Metaphor

Imagine a tangled fabric:
- Pull one thread (patch) โ nearby threads shift slightly
- Push it back (revert) โ not all threads go exactly back

Thus:  
> Revert patches **dampen** the effects, but **cannot guarantee perfect reset**.

---

## ๐ธ๐ฆ ุงูุนุฑุจูุฉ

ูุฐุง ุงูููู ูุดุฑุญ ุฃุญุฏ ุงููููุฏ ุงูุฃุณุงุณูุฉ ูู ุชุนุฏูู ุงููุดูุฑ (Decoder):
ููุงุฐุง ูุง ูููููุง ุฏุงุฆูุงู ุงูุชุฑุงุฌุน ุจูุณุจุฉ 100% ุญุชู ูุน ูุฌูุฏ ููู patch ูุธููุ

---

### โ ูุง ูู ุงูุชุฏุงุฎู ุงูุนุตุจูุ

ูู ุงููุถุงุกุงุช ุงููุชุฌููุฉ ุนุงููุฉ ุงูุฃุจุนุงุฏ (ููุง ูู ุงูููุงุฐุฌ ุงููุบููุฉ ุงููุจูุฑุฉ)ุ  
**ุงูุนุตุจููุงุช ูุง ุชุนูู ุจุดูู ูุณุชูู ุชูุงูุงู**.  
ูู ุนุตุจูู ูุณุงูู ูู ุงููุงุชุฌ ุจุดูู ุบูุฑ ุฎุทู ูุญุณุจ ุงูุณูุงู.

ุจุงูุชุงููุ ุชุนุฏูู ุนุตุจูู ูุงุญุฏ ูุฏ ูุคุซุฑ ููููุงู ุนูู ุงูุขุฎุฑูู โ ุฎุงุตุฉ ุนูุฏูุง:

- ุชููู ุงููุชุฌูุงุช ุงููุฌุงูุฑุฉ ูุดุงุจูุฉ ูู ุงูุงุชุฌุงู  
- ุชุญุฏุซ ุชุฏุงุฎูุงุช ูู ุงูุชูุนูู ุฏุงุฎู ุงูุทุจูุฉ  
- ุชุชุถุฎู ุงูุชุฃุซูุฑุงุช ุจุณุจุจ ุงูุทุจูุงุช ุงููุงุญูุฉ ุฃู `layernorm`

---

### ๐ฏ ุงูุชุฑุงุฌุน โ ุงูุฅูุบุงุก ุงููุงูู

ุญุชู ูู ูููุง ุจุฅุฑุฌุงุน ูููุงุณ ุงูุนุตุจูู (ูุซู 0.04 โ 1.0)ุ  
ูู ูุชููู ูู ุนูุณ ุงูุงูุฌุฑุงู ูู ุงูุญุงูุฉ ุงููุงุชุฌ ุนู ุงูุชุนุฏูู ุงูุณุงุจู.

ูุฐู ููุณุช ูุดููุฉ โ ุจู **ุฎุงุตูุฉ ุฑูุงุถูุฉ ูู ุงููุถุงุกุงุช ุงููุชุดุงุจูุฉ**.

---

### ๐งฌ ุชุดุจูู ุงููุณูุฌ

ุชุฎูู ูุณูุฌูุง ูุนููุฏูุง:
- ุนูุฏ ุณุญุจ ุฎูุท ูุงุญุฏ (Patch)ุ ุชุชุญุฑู ุงูุฎููุท ุงููุฌุงูุฑุฉ
- ุนูุฏ ุฅุฑุฌุงุนูุ ูุง ุชุนูุฏ ุงูุฎููุท ุจููุณ ุงูุชุฑุชูุจ ุงููุงูู

ุงููุชูุฌุฉ:
> ุงูุชุฑุงุฌุน ููููู ุงูุชุฃุซูุฑ โ ูููู ูุง ููุนูุฏ ูู ุดูุก ููุง ูุงู ุจุงูุถุจุท.

---

